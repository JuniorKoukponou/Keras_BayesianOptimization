{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [How to do Hyper-parameters search with Bayesian optimization for Keras model](https://www.dlology.com/blog/how-to-do-hyperparameter-search-with-baysian-optimization-for-keras-model/) | DLology Blog\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-06T06:24:28.869657Z",
     "start_time": "2019-04-06T06:24:28.864670Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install bayesian-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-06T06:24:32.239836Z",
     "start_time": "2019-04-06T06:24:29.062169Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-06T06:24:32.331980Z",
     "start_time": "2019-04-06T06:24:32.239836Z"
    }
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10\n",
    "\n",
    "def get_input_datasets(use_bfloat16=False):\n",
    "    \"\"\"Downloads the MNIST dataset and creates train and eval dataset objects.\n",
    "\n",
    "    Args:\n",
    "      use_bfloat16: Boolean to determine if input should be cast to bfloat16\n",
    "\n",
    "    Returns:\n",
    "      Train dataset, eval dataset and input shape.\n",
    "\n",
    "    \"\"\"\n",
    "    # input image dimensions\n",
    "    img_rows, img_cols = 28, 28\n",
    "    cast_dtype = tf.bfloat16 if use_bfloat16 else tf.float32\n",
    "\n",
    "    # the data, split between train and test sets\n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "    if tf.keras.backend.image_data_format() == 'channels_first':\n",
    "        x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "        x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "        input_shape = (1, img_rows, img_cols)\n",
    "    else:\n",
    "        x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "        x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "        input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "\n",
    "    # convert class vectors to binary class matrices\n",
    "    y_train = tf.keras.utils.to_categorical(y_train, NUM_CLASSES)\n",
    "    y_test = tf.keras.utils.to_categorical(y_test, NUM_CLASSES)\n",
    "\n",
    "    # train dataset\n",
    "    train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "    train_ds = train_ds.repeat()\n",
    "    train_ds = train_ds.map(lambda x, y: (tf.cast(x, cast_dtype), y))\n",
    "    train_ds = train_ds.batch(64, drop_remainder=True)\n",
    "\n",
    "    # eval dataset\n",
    "    eval_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "    eval_ds = eval_ds.repeat()\n",
    "    eval_ds = eval_ds.map(lambda x, y: (tf.cast(x, cast_dtype), y))\n",
    "    eval_ds = eval_ds.batch(64, drop_remainder=True)\n",
    "\n",
    "    return train_ds, eval_ds, input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-06T06:25:50.799831Z",
     "start_time": "2019-04-06T06:25:50.766873Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Dropout, BatchNormalization, MaxPooling2D, Flatten, Activation\n",
    "from tensorflow.python.keras.optimizer_v2 import rmsprop\n",
    "\n",
    "\n",
    "def get_model(input_shape, dropout2_rate=0.5, dense_1_neurons=128):\n",
    "    \"\"\"Builds a Sequential CNN model to recognize MNIST.\n",
    "\n",
    "    Args:\n",
    "      input_shape: Shape of the input depending on the `image_data_format`.\n",
    "      dropout2_rate: float between 0 and 1. Fraction of the input units to drop for `dropout_2` layer.\n",
    "      dense_1_neurons: Number of neurons for `dense1` layer.\n",
    "\n",
    "    Returns:\n",
    "      a Keras model\n",
    "\n",
    "    \"\"\"\n",
    "    # Reset the tensorflow backend session.\n",
    "    # tf.keras.backend.clear_session()\n",
    "    # Define a CNN model to recognize MNIST.\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     input_shape=input_shape,\n",
    "                     name=\"conv2d_1\"))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', name=\"conv2d_2\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), name=\"maxpool2d_1\"))\n",
    "    model.add(Dropout(0.25, name=\"dropout_1\"))\n",
    "    model.add(Flatten(name=\"flatten\"))\n",
    "    model.add(Dense(dense_1_neurons, activation='relu', name=\"dense_1\"))\n",
    "    model.add(Dropout(dropout2_rate, name=\"dropout_2\"))\n",
    "    model.add(Dense(NUM_CLASSES, activation='softmax', name=\"dense_2\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-06T06:25:56.072655Z",
     "start_time": "2019-04-06T06:25:53.790470Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ds, eval_ds, input_shape = get_input_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-06T06:39:58.600411Z",
     "start_time": "2019-04-06T06:39:58.573481Z"
    }
   },
   "outputs": [],
   "source": [
    "def fit_with(input_shape, verbose, dropout2_rate, dense_1_neurons_x128, lr):\n",
    "\n",
    "    # Create the model using a specified hyperparameters.\n",
    "    dense_1_neurons = max(int(dense_1_neurons_x128 * 128), 128)\n",
    "    model = get_model(input_shape, dropout2_rate, dense_1_neurons)\n",
    "\n",
    "    # Train the model for a specified number of epochs.\n",
    "    optimizer = rmsprop.RMSProp(learning_rate=lr)\n",
    "    model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Train the model with the train dataset.\n",
    "    model.fit(x=train_ds, epochs=1, steps_per_epoch=468,\n",
    "              batch_size=64, verbose=verbose)\n",
    "\n",
    "    # Evaluate the model with the eval dataset.\n",
    "    score = model.evaluate(eval_ds, steps=10, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "\n",
    "    # Return the accuracy.\n",
    "\n",
    "    return score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-06T06:39:59.098040Z",
     "start_time": "2019-04-06T06:39:59.093055Z"
    }
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "verbose = 1\n",
    "fit_with_partial = partial(fit_with, input_shape, verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-06T06:40:21.602188Z",
     "start_time": "2019-04-06T06:39:59.516917Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468/468 [==============================] - 4s 8ms/step - loss: 0.2689 - acc: 0.9198\n",
      "Test loss: 0.05191548839211464\n",
      "Test accuracy: 0.9796875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9796875"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_with_partial(dropout2_rate=0.5, lr=0.001, dense_1_neurons_x128=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The BayesianOptimization object will work out of the box without much tuning needed. The main method you should be aware of is `maximize`, which does exactly what you think it does.\n",
    "\n",
    "There are many parameters you can pass to maximize, nonetheless, the most important ones are:\n",
    "- `n_iter`: How many steps of bayesian optimization you want to perform. The more steps the more likely to find a good maximum you are.\n",
    "- `init_points`: How many steps of **random** exploration you want to perform. Random exploration can help by diversifying the exploration space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-06T06:36:59.194087Z",
     "start_time": "2019-04-06T06:28:48.327088Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | dense_... | dropou... |    lr     |\n",
      "-------------------------------------------------------------\n",
      "468/468 [==============================] - 4s 8ms/step - loss: 0.5582 - acc: 0.8414\n",
      "Test loss: 0.2389216348528862\n",
      "Test accuracy: 0.91875\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.9187  \u001b[0m | \u001b[0m 1.817   \u001b[0m | \u001b[0m 0.3881  \u001b[0m | \u001b[0m 0.000101\u001b[0m |\n",
      "468/468 [==============================] - 4s 8ms/step - loss: 0.2053 - acc: 0.9380\n",
      "Test loss: 0.054840138740837575\n",
      "Test accuracy: 0.978125\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.9781  \u001b[0m | \u001b[95m 1.565   \u001b[0m | \u001b[95m 0.1587  \u001b[0m | \u001b[95m 0.001014\u001b[0m |\n",
      "468/468 [==============================] - 4s 8ms/step - loss: 0.2131 - acc: 0.9362\n",
      "Test loss: 0.05061369054019451\n",
      "Test accuracy: 0.98125\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m 0.9812  \u001b[0m | \u001b[95m 1.31    \u001b[0m | \u001b[95m 0.2382  \u001b[0m | \u001b[95m 0.004028\u001b[0m |\n",
      "468/468 [==============================] - 4s 8ms/step - loss: 0.2352 - acc: 0.9286\n",
      "Test loss: 0.062168491538614035\n",
      "Test accuracy: 0.9796875\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.9797  \u001b[0m | \u001b[0m 2.085   \u001b[0m | \u001b[0m 0.2677  \u001b[0m | \u001b[0m 0.006884\u001b[0m |\n",
      "468/468 [==============================] - 4s 8ms/step - loss: 0.3745 - acc: 0.8879\n",
      "Test loss: 0.09099236726760865\n",
      "Test accuracy: 0.971875\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.9719  \u001b[0m | \u001b[0m 1.35    \u001b[0m | \u001b[0m 0.4512  \u001b[0m | \u001b[0m 0.000371\u001b[0m |\n",
      "468/468 [==============================] - 4s 8ms/step - loss: 0.2471 - acc: 0.9240\n",
      "Test loss: 0.06053957613185048\n",
      "Test accuracy: 0.9796875\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.9797  \u001b[0m | \u001b[0m 2.375   \u001b[0m | \u001b[0m 0.2669  \u001b[0m | \u001b[0m 0.005631\u001b[0m |\n",
      "468/468 [==============================] - 4s 8ms/step - loss: 0.2811 - acc: 0.9184\n",
      "Test loss: 0.05370073616504669\n",
      "Test accuracy: 0.978125\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.9781  \u001b[0m | \u001b[0m 1.209   \u001b[0m | \u001b[0m 0.1792  \u001b[0m | \u001b[0m 0.008027\u001b[0m |\n",
      "468/468 [==============================] - 4s 8ms/step - loss: 0.2364 - acc: 0.9280\n",
      "Test loss: 0.0981404937338084\n",
      "Test accuracy: 0.971875\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.9719  \u001b[0m | \u001b[0m 3.03    \u001b[0m | \u001b[0m 0.2254  \u001b[0m | \u001b[0m 0.006954\u001b[0m |\n",
      "468/468 [==============================] - 4s 8ms/step - loss: 0.2197 - acc: 0.9354\n",
      "Test loss: 0.049751975061371925\n",
      "Test accuracy: 0.984375\n",
      "| \u001b[95m 9       \u001b[0m | \u001b[95m 0.9844  \u001b[0m | \u001b[95m 2.828   \u001b[0m | \u001b[95m 0.4578  \u001b[0m | \u001b[95m 0.000941\u001b[0m |\n",
      "468/468 [==============================] - 4s 8ms/step - loss: 0.2802 - acc: 0.9187\n",
      "Test loss: 0.08437592722475529\n",
      "Test accuracy: 0.971875\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.9719  \u001b[0m | \u001b[0m 0.9859  \u001b[0m | \u001b[0m 0.1679  \u001b[0m | \u001b[0m 0.008794\u001b[0m |\n",
      "468/468 [==============================] - 4s 8ms/step - loss: 0.3782 - acc: 0.8881\n",
      "Test loss: 0.10996419470757246\n",
      "Test accuracy: 0.965625\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.9656  \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.01    \u001b[0m |\n",
      "468/468 [==============================] - 4s 9ms/step - loss: 0.3385 - acc: 0.9065\n",
      "Test loss: 0.08715003542602062\n",
      "Test accuracy: 0.96875\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.9688  \u001b[0m | \u001b[0m 3.1     \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.01    \u001b[0m |\n",
      "468/468 [==============================] - 4s 8ms/step - loss: 0.4809 - acc: 0.8696\n",
      "Test loss: 0.24387055933475493\n",
      "Test accuracy: 0.925\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.925   \u001b[0m | \u001b[0m 2.198   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.0001  \u001b[0m |\n",
      "468/468 [==============================] - 4s 9ms/step - loss: 0.3548 - acc: 0.8989\n",
      "Test loss: 0.07344335494562984\n",
      "Test accuracy: 0.975\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.975   \u001b[0m | \u001b[0m 2.348   \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.01    \u001b[0m |\n",
      "468/468 [==============================] - 4s 9ms/step - loss: 0.3099 - acc: 0.9079\n",
      "Test loss: 0.10711358338594437\n",
      "Test accuracy: 0.965625\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.9656  \u001b[0m | \u001b[0m 2.612   \u001b[0m | \u001b[0m 0.3854  \u001b[0m | \u001b[0m 0.01    \u001b[0m |\n",
      "468/468 [==============================] - 4s 9ms/step - loss: 0.4758 - acc: 0.8741\n",
      "Test loss: 0.21829677745699883\n",
      "Test accuracy: 0.9296875\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.9297  \u001b[0m | \u001b[0m 3.1     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.0001  \u001b[0m |\n",
      "468/468 [==============================] - 4s 9ms/step - loss: 0.6822 - acc: 0.8075\n",
      "Test loss: 0.2787873461842537\n",
      "Test accuracy: 0.9046875\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.9047  \u001b[0m | \u001b[0m 1.094   \u001b[0m | \u001b[0m 0.404   \u001b[0m | \u001b[0m 0.0001  \u001b[0m |\n",
      "468/468 [==============================] - 5s 10ms/step - loss: 0.5840 - acc: 0.8417\n",
      "Test loss: 0.2642665967345238\n",
      "Test accuracy: 0.9125\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.9125  \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.0001  \u001b[0m |\n",
      "468/468 [==============================] - 4s 9ms/step - loss: 0.3248 - acc: 0.9091\n",
      "Test loss: 0.06913231052458287\n",
      "Test accuracy: 0.9765625\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.9766  \u001b[0m | \u001b[0m 2.759   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.01    \u001b[0m |\n",
      "468/468 [==============================] - 4s 8ms/step - loss: 0.3641 - acc: 0.8961\n",
      "Test loss: 0.22782635539770127\n",
      "Test accuracy: 0.9171875\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.9172  \u001b[0m | \u001b[0m 1.543   \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.01    \u001b[0m |\n",
      "=============================================================\n",
      "Iteration 0: \n",
      "\t{'params': {'dropout2_rate': 0.38812979737686326, 'lr': 0.00010113231069171439, 'dense_1_neurons_x128': 1.817448410345663}, 'target': 0.918749988079071}\n",
      "Iteration 1: \n",
      "\t{'params': {'dropout2_rate': 0.15870235632684523, 'lr': 0.0010141520882110983, 'dense_1_neurons_x128': 1.5651316597900475}, 'target': 0.9781249761581421}\n",
      "Iteration 2: \n",
      "\t{'params': {'dropout2_rate': 0.2382242908172191, 'lr': 0.004027997994883633, 'dense_1_neurons_x128': 1.309772465030876}, 'target': 0.981249988079071}\n",
      "Iteration 3: \n",
      "\t{'params': {'dropout2_rate': 0.26767780576131794, 'lr': 0.00688367305392792, 'dense_1_neurons_x128': 2.0853968148073854}, 'target': 0.979687511920929}\n",
      "Iteration 4: \n",
      "\t{'params': {'dropout2_rate': 0.4512469745563782, 'lr': 0.00037113717265946903, 'dense_1_neurons_x128': 1.3497949494093384}, 'target': 0.971875011920929}\n",
      "Iteration 5: \n",
      "\t{'params': {'dropout2_rate': 0.2669219209468508, 'lr': 0.005631029301612942, 'dense_1_neurons_x128': 2.375028522392485}, 'target': 0.979687511920929}\n",
      "Iteration 6: \n",
      "\t{'params': {'dropout2_rate': 0.17924059563395153, 'lr': 0.008027371229887814, 'dense_1_neurons_x128': 1.2088512649095144}, 'target': 0.9781249761581421}\n",
      "Iteration 7: \n",
      "\t{'params': {'dropout2_rate': 0.22536967126369714, 'lr': 0.0069539938951262105, 'dense_1_neurons_x128': 3.0301754665826746}, 'target': 0.971875011920929}\n",
      "Iteration 8: \n",
      "\t{'params': {'dropout2_rate': 0.45784266540153895, 'lr': 0.0009419376925608015, 'dense_1_neurons_x128': 2.8280561350512845}, 'target': 0.984375}\n",
      "Iteration 9: \n",
      "\t{'params': {'dropout2_rate': 0.16793216782582757, 'lr': 0.00879361078395119, 'dense_1_neurons_x128': 0.9859205231123412}, 'target': 0.971875011920929}\n",
      "Iteration 10: \n",
      "\t{'params': {'dropout2_rate': 0.5, 'lr': 0.01, 'dense_1_neurons_x128': 0.9}, 'target': 0.965624988079071}\n",
      "Iteration 11: \n",
      "\t{'params': {'dropout2_rate': 0.5, 'lr': 0.01, 'dense_1_neurons_x128': 3.1}, 'target': 0.96875}\n",
      "Iteration 12: \n",
      "\t{'params': {'dropout2_rate': 0.1, 'lr': 0.0001, 'dense_1_neurons_x128': 2.197640063050872}, 'target': 0.925000011920929}\n",
      "Iteration 13: \n",
      "\t{'params': {'dropout2_rate': 0.5, 'lr': 0.01, 'dense_1_neurons_x128': 2.3480052621751404}, 'target': 0.9750000238418579}\n",
      "Iteration 14: \n",
      "\t{'params': {'dropout2_rate': 0.38541741438100613, 'lr': 0.01, 'dense_1_neurons_x128': 2.612323476531291}, 'target': 0.965624988079071}\n",
      "Iteration 15: \n",
      "\t{'params': {'dropout2_rate': 0.1, 'lr': 0.0001, 'dense_1_neurons_x128': 3.1}, 'target': 0.9296875}\n",
      "Iteration 16: \n",
      "\t{'params': {'dropout2_rate': 0.40404334217748467, 'lr': 0.0001, 'dense_1_neurons_x128': 1.0940417319128386}, 'target': 0.9046875238418579}\n",
      "Iteration 17: \n",
      "\t{'params': {'dropout2_rate': 0.1, 'lr': 0.0001, 'dense_1_neurons_x128': 0.9}, 'target': 0.9125000238418579}\n",
      "Iteration 18: \n",
      "\t{'params': {'dropout2_rate': 0.1, 'lr': 0.01, 'dense_1_neurons_x128': 2.759165230348048}, 'target': 0.9765625}\n",
      "Iteration 19: \n",
      "\t{'params': {'dropout2_rate': 0.5, 'lr': 0.01, 'dense_1_neurons_x128': 1.542631744033199}, 'target': 0.917187511920929}\n",
      "{'params': {'dropout2_rate': 0.45784266540153895, 'lr': 0.0009419376925608015, 'dense_1_neurons_x128': 2.8280561350512845}, 'target': 0.984375}\n"
     ]
    }
   ],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "# Bounded region of parameter space\n",
    "pbounds = {'dropout2_rate': (0.1, 0.5), 'lr': (1e-4, 1e-2), \"dense_1_neurons_x128\": (0.9, 3.1)}\n",
    "\n",
    "optimizer = BayesianOptimization(\n",
    "    f=fit_with_partial,\n",
    "    pbounds=pbounds,\n",
    "    verbose=2,  # verbose = 1 prints only when a maximum is observed, verbose = 0 is silent\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "optimizer.maximize(init_points=10, n_iter=10,)\n",
    "\n",
    "\n",
    "for i, res in enumerate(optimizer.res):\n",
    "    print(\"Iteration {}: \\n\\t{}\".format(i, res))\n",
    "\n",
    "print(optimizer.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-06T06:40:21.609170Z",
     "start_time": "2019-04-06T06:40:21.604213Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'params': {'dropout2_rate': 0.45784266540153895, 'lr': 0.0009419376925608015, 'dense_1_neurons_x128': 2.8280561350512845}, 'target': 0.984375}\n"
     ]
    }
   ],
   "source": [
    "print(optimizer.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
