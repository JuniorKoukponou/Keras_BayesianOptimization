{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [How to do Hyper-parameters search with Bayesian optimization for Keras model](https://www.dlology.com/blog/how-to-do-hyperparameter-search-with-baysian-optimization-for-keras-model/) | DLology Blog\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-06T02:22:23.566450Z",
     "start_time": "2019-04-06T02:22:23.561467Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install bayesian-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-06T05:51:39.766105Z",
     "start_time": "2019-04-06T05:51:36.284034Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-06T05:51:39.857259Z",
     "start_time": "2019-04-06T05:51:39.766105Z"
    }
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10\n",
    "\n",
    "def get_input_datasets(use_bfloat16=False):\n",
    "    \"\"\"Downloads the MNIST dataset and creates train and eval dataset objects.\n",
    "\n",
    "    Args:\n",
    "      use_bfloat16: Boolean to determine if input should be cast to bfloat16\n",
    "\n",
    "    Returns:\n",
    "      Train dataset, eval dataset and input shape.\n",
    "\n",
    "    \"\"\"\n",
    "    # input image dimensions\n",
    "    img_rows, img_cols = 28, 28\n",
    "    cast_dtype = tf.bfloat16 if use_bfloat16 else tf.float32\n",
    "\n",
    "    # the data, split between train and test sets\n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "    if tf.keras.backend.image_data_format() == 'channels_first':\n",
    "        x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "        x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "        input_shape = (1, img_rows, img_cols)\n",
    "    else:\n",
    "        x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "        x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "        input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "\n",
    "    # convert class vectors to binary class matrices\n",
    "    y_train = tf.keras.utils.to_categorical(y_train, NUM_CLASSES)\n",
    "    y_test = tf.keras.utils.to_categorical(y_test, NUM_CLASSES)\n",
    "\n",
    "    # train dataset\n",
    "    train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "    train_ds = train_ds.repeat()\n",
    "    train_ds = train_ds.map(lambda x, y: (tf.cast(x, cast_dtype), y))\n",
    "    train_ds = train_ds.batch(64, drop_remainder=True)\n",
    "\n",
    "    # eval dataset\n",
    "    eval_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "    eval_ds = eval_ds.repeat()\n",
    "    eval_ds = eval_ds.map(lambda x, y: (tf.cast(x, cast_dtype), y))\n",
    "    eval_ds = eval_ds.batch(64, drop_remainder=True)\n",
    "\n",
    "    return train_ds, eval_ds, input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-06T05:51:39.896304Z",
     "start_time": "2019-04-06T05:51:39.857259Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Dropout, BatchNormalization, MaxPooling2D, Flatten, Activation\n",
    "from tensorflow.python.keras.optimizer_v2 import rmsprop\n",
    "\n",
    "\n",
    "def get_model(input_shape, dropout2_rate=0.5):\n",
    "    \"\"\"Builds a Sequential CNN model to recognize MNIST.\n",
    "\n",
    "    Args:\n",
    "      input_shape: Shape of the input depending on the `image_data_format`.\n",
    "      dropout2_rate: float between 0 and 1. Fraction of the input units to drop for `dense1` layer.\n",
    "\n",
    "    Returns:\n",
    "      a Keras model\n",
    "\n",
    "    \"\"\"\n",
    "    # Reset the tensorflow backend session.\n",
    "    # tf.keras.backend.clear_session()\n",
    "    # Define a CNN model to recognize MNIST.\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     input_shape=input_shape,\n",
    "                     name=\"conv2d_1\"))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', name=\"conv2d_2\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), name=\"maxpool2d_1\"))\n",
    "    model.add(Dropout(0.25, name=\"dropout_1\"))\n",
    "    model.add(Flatten(name=\"flatten\"))\n",
    "    model.add(Dense(128, activation='relu', name=\"dense_1\"))\n",
    "    model.add(Dropout(dropout2_rate, name=\"dropout_2\"))\n",
    "    model.add(Dense(NUM_CLASSES, activation='softmax', name=\"dense_2\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-06T05:51:41.966926Z",
     "start_time": "2019-04-06T05:51:39.898277Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ds, eval_ds, input_shape = get_input_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-06T05:51:58.564304Z",
     "start_time": "2019-04-06T05:51:58.544351Z"
    }
   },
   "outputs": [],
   "source": [
    "def fit_with(input_shape, verbose, dropout2_rate, lr):\n",
    "\n",
    "    # Create the model using a specified hyperparameters.\n",
    "    model = get_model(input_shape, dropout2_rate)\n",
    "\n",
    "    # Train the model for a specified number of epochs.\n",
    "    optimizer = rmsprop.RMSProp(learning_rate=lr)\n",
    "    model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Train the model with the train dataset.\n",
    "    model.fit(x=train_ds, epochs=1, steps_per_epoch=468,\n",
    "              batch_size=64, verbose=verbose)\n",
    "\n",
    "    # Evaluate the model with the eval dataset.\n",
    "    score = model.evaluate(eval_ds, steps=10, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "\n",
    "    # Return the accuracy.\n",
    "\n",
    "    return score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-06T05:51:58.990505Z",
     "start_time": "2019-04-06T05:51:58.984520Z"
    }
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "verbose = 1\n",
    "fit_with_partial = partial(fit_with, input_shape, verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-06T05:51:59.860498Z",
     "start_time": "2019-04-06T05:51:59.856509Z"
    }
   },
   "outputs": [],
   "source": [
    "# fit_with_partial(dropout2_rate=0.5, lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The BayesianOptimization object will work out of the box without much tuning needed. The main method you should be aware of is `maximize`, which does exactly what you think it does.\n",
    "\n",
    "There are many parameters you can pass to maximize, nonetheless, the most important ones are:\n",
    "- `n_iter`: How many steps of bayesian optimization you want to perform. The more steps the more likely to find a good maximum you are.\n",
    "- `init_points`: How many steps of **random** exploration you want to perform. Random exploration can help by diversifying the exploration space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-06T03:00:30.105708Z",
     "start_time": "2019-04-06T02:51:28.687882Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | dropou... |    lr     |\n",
      "-------------------------------------------------\n",
      "468/468 [==============================] - 4s 8ms/step - loss: 0.2575 - acc: 0.9246\n",
      "Test loss: 0.061651699058711526\n",
      "Test accuracy: 0.9828125\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.9828  \u001b[0m | \u001b[0m 0.2668  \u001b[0m | \u001b[0m 0.007231\u001b[0m |\n",
      "468/468 [==============================] - 4s 8ms/step - loss: 0.2065 - acc: 0.9363\n",
      "Test loss: 0.04886047407053411\n",
      "Test accuracy: 0.9828125\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.9828  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.003093\u001b[0m |\n",
      "468/468 [==============================] - 4s 8ms/step - loss: 0.2199 - acc: 0.9336\n",
      "Test loss: 0.05553104653954506\n",
      "Test accuracy: 0.98125\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.9812  \u001b[0m | \u001b[0m 0.1587  \u001b[0m | \u001b[0m 0.001014\u001b[0m |\n",
      "468/468 [==============================] - 4s 9ms/step - loss: 0.2075 - acc: 0.9390\n",
      "Test loss: 0.04128134781494737\n",
      "Test accuracy: 0.9890625\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m 0.9891  \u001b[0m | \u001b[95m 0.1745  \u001b[0m | \u001b[95m 0.003521\u001b[0m |\n",
      "468/468 [==============================] - 4s 9ms/step - loss: 0.2304 - acc: 0.9304\n",
      "Test loss: 0.05252270437777042\n",
      "Test accuracy: 0.984375\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.9844  \u001b[0m | \u001b[0m 0.2587  \u001b[0m | \u001b[0m 0.005434\u001b[0m |\n",
      "468/468 [==============================] - 4s 9ms/step - loss: 0.2587 - acc: 0.9207\n",
      "Test loss: 0.055292441183701156\n",
      "Test accuracy: 0.978125\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.9781  \u001b[0m | \u001b[0m 0.2677  \u001b[0m | \u001b[0m 0.006884\u001b[0m |\n",
      "468/468 [==============================] - 4s 9ms/step - loss: 0.2714 - acc: 0.9216\n",
      "Test loss: 0.06474586613476277\n",
      "Test accuracy: 0.9796875\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.9797  \u001b[0m | \u001b[0m 0.1818  \u001b[0m | \u001b[0m 0.008793\u001b[0m |\n",
      "468/468 [==============================] - 4s 9ms/step - loss: 0.2823 - acc: 0.9163\n",
      "Test loss: 0.07059854744002222\n",
      "Test accuracy: 0.9796875\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.9797  \u001b[0m | \u001b[0m 0.111   \u001b[0m | \u001b[0m 0.006738\u001b[0m |\n",
      "468/468 [==============================] - 4s 9ms/step - loss: 0.2654 - acc: 0.9230\n",
      "Test loss: 0.04820956862531602\n",
      "Test accuracy: 0.9828125\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.9828  \u001b[0m | \u001b[0m 0.2669  \u001b[0m | \u001b[0m 0.005631\u001b[0m |\n",
      "468/468 [==============================] - 4s 9ms/step - loss: 0.1838 - acc: 0.9437\n",
      "Test loss: 0.05831079101189971\n",
      "Test accuracy: 0.9765625\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.9766  \u001b[0m | \u001b[0m 0.1562  \u001b[0m | \u001b[0m 0.002061\u001b[0m |\n",
      "468/468 [==============================] - 4s 9ms/step - loss: 0.3490 - acc: 0.9013\n",
      "Test loss: 0.09265917297452689\n",
      "Test accuracy: 0.965625\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.9656  \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.01    \u001b[0m |\n",
      "468/468 [==============================] - 4s 9ms/step - loss: 0.6745 - acc: 0.8069\n",
      "Test loss: 0.27197607755661013\n",
      "Test accuracy: 0.9125\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.9125  \u001b[0m | \u001b[0m 0.4107  \u001b[0m | \u001b[0m 0.0001  \u001b[0m |\n",
      "468/468 [==============================] - 4s 9ms/step - loss: 0.7517 - acc: 0.7855\n",
      "Test loss: 0.298919640481472\n",
      "Test accuracy: 0.89375\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.8938  \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.0001  \u001b[0m |\n",
      "468/468 [==============================] - 4s 9ms/step - loss: 0.3356 - acc: 0.9023\n",
      "Test loss: 0.0727097101509571\n",
      "Test accuracy: 0.9765625\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.9766  \u001b[0m | \u001b[0m 0.3502  \u001b[0m | \u001b[0m 0.01    \u001b[0m |\n",
      "468/468 [==============================] - 4s 9ms/step - loss: 0.5709 - acc: 0.8419\n",
      "Test loss: 0.25102778673172\n",
      "Test accuracy: 0.9234375\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.9234  \u001b[0m | \u001b[0m 0.2115  \u001b[0m | \u001b[0m 0.0001  \u001b[0m |\n",
      "468/468 [==============================] - 4s 9ms/step - loss: 0.3611 - acc: 0.8917\n",
      "Test loss: 0.08683416619896889\n",
      "Test accuracy: 0.975\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.975   \u001b[0m | \u001b[0m 0.4578  \u001b[0m | \u001b[0m 0.01    \u001b[0m |\n",
      "468/468 [==============================] - 4s 9ms/step - loss: 0.3591 - acc: 0.8887\n",
      "Test loss: 0.19576222822070122\n",
      "Test accuracy: 0.9359375\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.9359  \u001b[0m | \u001b[0m 0.3886  \u001b[0m | \u001b[0m 0.01    \u001b[0m |\n",
      "468/468 [==============================] - 4s 9ms/step - loss: 0.6169 - acc: 0.8233\n",
      "Test loss: 0.2819798469543457\n",
      "Test accuracy: 0.90625\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.9062  \u001b[0m | \u001b[0m 0.3229  \u001b[0m | \u001b[0m 0.0001  \u001b[0m |\n",
      "468/468 [==============================] - 4s 9ms/step - loss: 0.2907 - acc: 0.9185\n",
      "Test loss: 0.08198854299262166\n",
      "Test accuracy: 0.9765625\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.9766  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.01    \u001b[0m |\n",
      "468/468 [==============================] - 4s 9ms/step - loss: 0.6423 - acc: 0.8169\n",
      "Test loss: 0.274230869114399\n",
      "Test accuracy: 0.9046875\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.9047  \u001b[0m | \u001b[0m 0.3633  \u001b[0m | \u001b[0m 0.0001  \u001b[0m |\n",
      "=================================================\n",
      "Iteration 0: \n",
      "\t{'params': {'lr': 0.007231212485077366, 'dropout2_rate': 0.2668088018810296}, 'target': 0.9828125238418579}\n",
      "Iteration 1: \n",
      "\t{'params': {'lr': 0.003093092469055214, 'dropout2_rate': 0.10004574992693796}, 'target': 0.9828125238418579}\n",
      "Iteration 2: \n",
      "\t{'params': {'lr': 0.0010141520882110983, 'dropout2_rate': 0.15870235632684523}, 'target': 0.981249988079071}\n",
      "Iteration 3: \n",
      "\t{'params': {'lr': 0.003521051197726173, 'dropout2_rate': 0.17450408455106836}, 'target': 0.989062488079071}\n",
      "Iteration 4: \n",
      "\t{'params': {'lr': 0.005434285666633234, 'dropout2_rate': 0.258706989692268}, 'target': 0.984375}\n",
      "Iteration 5: \n",
      "\t{'params': {'lr': 0.00688367305392792, 'dropout2_rate': 0.26767780576131794}, 'target': 0.9781249761581421}\n",
      "Iteration 6: \n",
      "\t{'params': {'lr': 0.00879336262027036, 'dropout2_rate': 0.18178089989260698}, 'target': 0.979687511920929}\n",
      "Iteration 7: \n",
      "\t{'params': {'lr': 0.0067376283507661824, 'dropout2_rate': 0.11095503727917047}, 'target': 0.979687511920929}\n",
      "Iteration 8: \n",
      "\t{'params': {'lr': 0.005631029301612942, 'dropout2_rate': 0.2669219209468508}, 'target': 0.9828125238418579}\n",
      "Iteration 9: \n",
      "\t{'params': {'lr': 0.0020612047419403, 'dropout2_rate': 0.15615477543809353}, 'target': 0.9765625}\n",
      "Iteration 10: \n",
      "\t{'params': {'lr': 0.01, 'dropout2_rate': 0.5}, 'target': 0.965624988079071}\n",
      "Iteration 11: \n",
      "\t{'params': {'lr': 0.0001, 'dropout2_rate': 0.4106528357804306}, 'target': 0.9125000238418579}\n",
      "Iteration 12: \n",
      "\t{'params': {'lr': 0.0001, 'dropout2_rate': 0.5}, 'target': 0.893750011920929}\n",
      "Iteration 13: \n",
      "\t{'params': {'lr': 0.01, 'dropout2_rate': 0.35016548035090245}, 'target': 0.9765625}\n",
      "Iteration 14: \n",
      "\t{'params': {'lr': 0.0001, 'dropout2_rate': 0.21145905847666743}, 'target': 0.9234374761581421}\n",
      "Iteration 15: \n",
      "\t{'params': {'lr': 0.01, 'dropout2_rate': 0.4578145303323835}, 'target': 0.9750000238418579}\n",
      "Iteration 16: \n",
      "\t{'params': {'lr': 0.01, 'dropout2_rate': 0.3886059690263741}, 'target': 0.9359375238418579}\n",
      "Iteration 17: \n",
      "\t{'params': {'lr': 0.0001, 'dropout2_rate': 0.32293032729216575}, 'target': 0.90625}\n",
      "Iteration 18: \n",
      "\t{'params': {'lr': 0.01, 'dropout2_rate': 0.1}, 'target': 0.9765625}\n",
      "Iteration 19: \n",
      "\t{'params': {'lr': 0.0001, 'dropout2_rate': 0.3633177397485205}, 'target': 0.9046875238418579}\n",
      "{'params': {'lr': 0.003521051197726173, 'dropout2_rate': 0.17450408455106836}, 'target': 0.989062488079071}\n"
     ]
    }
   ],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "# Bounded region of parameter space\n",
    "pbounds = {'dropout2_rate': (0.1, 0.5), 'lr': (1e-4, 1e-2)}\n",
    "\n",
    "optimizer = BayesianOptimization(\n",
    "    f=fit_with_partial,\n",
    "    pbounds=pbounds,\n",
    "    verbose=2,  # verbose = 1 prints only when a maximum is observed, verbose = 0 is silent\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "optimizer.maximize(init_points=10, n_iter=10,)\n",
    "\n",
    "\n",
    "for i, res in enumerate(optimizer.res):\n",
    "    print(\"Iteration {}: \\n\\t{}\".format(i, res))\n",
    "\n",
    "print(optimizer.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-06T03:22:22.531973Z",
     "start_time": "2019-04-06T03:22:22.525990Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'params': {'lr': 0.003521051197726173, 'dropout2_rate': 0.17450408455106836}, 'target': 0.989062488079071}\n"
     ]
    }
   ],
   "source": [
    "print(optimizer.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
